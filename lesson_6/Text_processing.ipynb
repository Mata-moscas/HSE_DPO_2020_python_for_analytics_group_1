{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python для анализа данных\n",
    "\n",
    "Валентин Бирюков, НИУ ВШЭ\n",
    "\n",
    "# Обработка текстов чем-то хитрее регулярок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Супер краткий экскурс в NLP\n",
    "\n",
    "## здесь текст!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 1\n",
    "### давайте научимся \"красиво\" считать количество слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=['One Cent, Two Cents, Old Cent, New Cent: All About Money'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(doc)\n",
    "count_vector=cv.fit_transform(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 7,\n",
       " 'cent': 2,\n",
       " 'two': 8,\n",
       " 'cents': 3,\n",
       " 'old': 6,\n",
       " 'new': 5,\n",
       " 'all': 1,\n",
       " 'about': 0,\n",
       " 'money': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# показать полученный словарный запас; числа - не счетчики! это позиция в разреженном векторе.\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix shape. 1 documents, 9 unique words\n",
    "count_vector.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any words eliminated internally? -- nope\n",
    "cv.stop_words_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один текст конечно хорошо, но мы хе хотим работать с текстАМИ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_in_the_hat_docs=[\n",
    "      \"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\",\n",
    "      \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\",\n",
    "      \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\",\n",
    "      \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\",\n",
    "      \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\" \n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs)\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 43)\n",
      "{'one': 28, 'cent': 8, 'two': 40, 'cents': 9, 'old': 26, 'new': 23, 'all': 1, 'about': 0, 'money': 22, 'cat': 7, 'in': 16, 'the': 37, 'hat': 13, 'learning': 19, 'library': 20, 'inside': 18, 'your': 42, 'outside': 30, 'human': 15, 'body': 4, 'oh': 25, 'things': 39, 'you': 41, 'can': 6, 'do': 10, 'that': 36, 'are': 2, 'good': 12, 'for': 11, 'staying': 34, 'healthy': 14, 'on': 27, 'beyond': 3, 'bugs': 5, 'insects': 17, 'there': 38, 'no': 24, 'place': 31, 'like': 21, 'space': 33, 'our': 29, 'solar': 32, 'system': 35}\n"
     ]
    }
   ],
   "source": [
    "print(count_vector.shape)\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было что то про стоп слова - это куда?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs,stop_words=[\"all\",\"in\",\"the\",\"is\",\"and\"])\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)\n",
    "count_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не на память же их все писать?\n",
    "Встроенный набор слов - английский, остальные надо подсовывать уже руками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs,stop_words=\"english\") \n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что делать со \"мутными языками\"? Наверное же стоп слова должны как-то \"статистически\" отличаться?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no', 'body', 'two', 'one', 'good', 'new', 'do', 'money', 'space', 'your', 'beyond', 'cent', 'that', 'are', 'system', 'place', 'on', 'there', 'cents', 'solar', 'can', 'healthy', 'our', 'oh', 'old', 'human', 'things', 'insects', 'staying', 'inside', 'you', 'bugs', 'for', 'like', 'outside'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs,min_df=2)\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)\n",
    "print(cv.stop_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no', 'body', 'two', 'one', 'good', 'new', 'do', 'money', 'space', 'your', 'beyond', 'cent', 'that', 'are', 'system', 'place', 'on', 'there', 'cents', 'solar', 'can', 'healthy', 'our', 'oh', 'old', 'human', 'things', 'insects', 'staying', 'inside', 'you', 'bugs', 'for', 'like', 'outside'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs,min_df=0.25)\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)\n",
    "print(cv.stop_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in', 'hat', 'library', 'about', 'the', 'cat', 'all', 'learning'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs,max_df=0.50)\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)\n",
    "print(cv.stop_words_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 2\n",
    "### Как-то почистим слова. А вдруг связки все же важны?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one': 25, 'cent': 8, 'two': 37, 'old': 23, 'new': 20, '_connector_': 0, 'about': 1, 'money': 19, 'cat': 7, 'the': 34, 'hat': 11, 'learn': 16, 'librari': 17, 'insid': 15, 'your': 39, 'outsid': 27, 'human': 13, 'bodi': 4, 'oh': 22, 'thing': 36, 'you': 38, 'can': 6, 'do': 9, 'that': 33, 'are': 2, 'good': 10, 'stay': 31, 'healthi': 12, 'on': 24, 'beyond': 3, 'bug': 5, 'insect': 14, 'there': 35, 'no': 21, 'place': 28, 'like': 18, 'space': 30, 'our': 26, 'solar': 29, 'system': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# init stemmer\n",
    "porter_stemmer=PorterStemmer()\n",
    "\n",
    "def my_cool_preprocessor(text):\n",
    "    \n",
    "    text=text.lower() \n",
    "    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "    text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n",
    "    \n",
    "    # stem words\n",
    "    words=re.split(\"\\\\s+\",text)\n",
    "    stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "cv = CountVectorizer(cat_in_the_hat_docs,preprocessor=my_cool_preprocessor)\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)\n",
    "print(cv.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 3\n",
    "### Слово - хорошо, но оно же зависит от контекста? Решение есть - ngrams!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one cent': 35, 'cent two': 19, 'two cent': 47, 'cent old': 18, 'old cent': 33, 'cent new': 17, 'new cent': 30, 'cent _connector_': 16, '_connector_ about': 0, 'about money': 7, 'money cat': 29, 'cat _connector_': 15, '_connector_ the': 2, 'the hat': 44, 'hat learn': 22, 'learn librari': 27, 'insid your': 26, 'your outsid': 50, 'outsid _connector_': 37, 'about _connector_': 5, '_connector_ human': 1, 'human bodi': 24, 'bodi cat': 12, 'oh _connector_': 32, '_connector_ thing': 3, 'thing you': 46, 'you can': 49, 'can do': 14, 'do that': 20, 'that are': 43, 'are good': 10, 'good _connector_': 21, '_connector_ you': 4, 'you _connector_': 48, 'about stay': 9, 'stay healthi': 41, 'healthi cat': 23, 'on beyond': 34, 'beyond bug': 11, 'bug _connector_': 13, 'about insect': 6, 'insect cat': 25, 'there no': 45, 'no place': 31, 'place like': 38, 'like space': 28, 'space _connector_': 40, 'about our': 8, 'our solar': 36, 'solar system': 39, 'system cat': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs,ngram_range=(2,2),preprocessor=my_cool_preprocessor)\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 4\n",
    "#### Смысл в слове - он где то в корнях/суффиксах и тд. то есть в маленьких кусах букв - что если побить так?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' o': 11, 'on': 77, 'ne': 67, 'e ': 36, ' c': 3, 'ce': 30, 'en': 40, 'nt': 72, 't ': 96, ' t': 14, 'tw': 102, 'wo': 109, 'o ': 73, 'ol': 76, 'ld': 58, 'd ': 33, ' n': 10, 'ew': 42, 'w ': 108, ' _': 0, '_c': 17, 'co': 31, 'nn': 69, 'ec': 38, 'ct': 32, 'to': 100, 'or': 79, 'r_': 84, '_ ': 16, ' a': 1, 'ab': 18, 'bo': 26, 'ou': 80, 'ut': 107, ' m': 9, 'mo': 64, 'ey': 43, 'y ': 110, 'ca': 29, 'at': 23, 'th': 99, 'he': 48, ' h': 6, 'ha': 47, ' s': 13, 's ': 89, ' l': 8, 'le': 59, 'ea': 37, 'ar': 22, 'rn': 88, 'n ': 65, 'li': 60, 'ib': 52, 'br': 27, 'ra': 85, 'ri': 87, 'i ': 51, ' i': 7, 'in': 55, 'ns': 71, 'si': 91, 'id': 53, ' y': 15, 'yo': 111, 'ur': 106, 'r ': 83, 'ts': 101, 'hu': 50, 'um': 105, 'ma': 63, 'an': 21, ' b': 2, 'od': 74, 'di': 34, 'oh': 75, 'h ': 46, 'hi': 49, 'ng': 68, 'g ': 44, 'u ': 103, ' d': 4, 'do': 35, 're': 86, ' g': 5, 'go': 45, 'oo': 78, 'st': 94, 'ta': 97, 'ay': 24, 'al': 20, 'lt': 61, 'be': 25, 'nd': 66, 'bu': 28, 'ug': 104, 'se': 90, 'er': 41, 'no': 70, ' p': 12, 'pl': 82, 'la': 57, 'ac': 19, 'ik': 54, 'ke': 56, 'sp': 93, 'pa': 81, 'so': 92, 'sy': 95, 'ys': 112, 'te': 98, 'em': 39, 'm ': 62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs,ngram_range=(2,2),preprocessor=my_cool_preprocessor,analyzer='char_wb')\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частотности-то что как достаем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"return n-gram counts in descending order of counts\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    results=[]\n",
    "    \n",
    "    # word index, count i\n",
    "    for idx, count in sorted_items:\n",
    "        \n",
    "        # get the ngram name\n",
    "        n_gram=feature_names[idx]\n",
    "        \n",
    "        # collect as a list of tuples\n",
    "        results.append((n_gram,count))\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass input=[\"One Cent, Two Cents, Old Cent, New Cent: All About Money (Cat in the Hat's Learning Library\", \"Inside Your Outside: All About the Human Body (Cat in the Hat's Learning Library)\", \"Oh, The Things You Can Do That Are Good for You: All About Staying Healthy (Cat in the Hat's Learning Library)\", \"On Beyond Bugs: All About Insects (Cat in the Hat's Learning Library)\", \"There's No Place Like Space: All About Our Solar System (Cat in the Hat's Learning Library)\"] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cent', 4),\n",
       " ('_connector_', 2),\n",
       " ('two cent', 1),\n",
       " ('two', 1),\n",
       " ('the hat', 1),\n",
       " ('the', 1),\n",
       " ('one cent', 1),\n",
       " ('one', 1),\n",
       " ('old cent', 1),\n",
       " ('old', 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(cat_in_the_hat_docs,ngram_range=(1,2),preprocessor=my_cool_preprocessor,max_features=100)\n",
    "count_vector=cv.fit_transform(cat_in_the_hat_docs)\n",
    "\n",
    "#sort the counts of first book title by descending order of counts\n",
    "sorted_items=sort_coo(count_vector[0].tocoo())\n",
    "\n",
    "#Get feature names (words/n-grams). It is sorted by position in sparse matrix\n",
    "feature_names=cv.get_feature_names()\n",
    "n_grams=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 5\n",
    "\n",
    "#### Слов в корпусе языка - большое количество. Надо как-то аккуратнее работать со словами... хеши!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute raw counts using hashing vectorizer\n",
    "# Small numbers of n_features can cause hash collisions\n",
    "hvectorizer = HashingVectorizer(n_features=10000,norm=None,alternate_sign=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts without any term frequency normalization\n",
    "X = hvectorizer.fit_transform(cat_in_the_hat_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 93)\t3.0\n",
      "  (0, 689)\t1.0\n",
      "  (0, 717)\t1.0\n",
      "  (0, 1664)\t1.0\n",
      "  (0, 2759)\t1.0\n",
      "  (0, 3124)\t1.0\n",
      "  (0, 4212)\t1.0\n",
      "  (0, 4380)\t1.0\n",
      "  (0, 5044)\t1.0\n",
      "  (0, 7353)\t1.0\n",
      "  (0, 8903)\t1.0\n",
      "  (0, 8958)\t1.0\n",
      "  (0, 9376)\t1.0\n",
      "  (0, 9402)\t1.0\n",
      "  (0, 9851)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# print populated columns of first document\n",
    "# format: (doc id, pos_in_matrix)  raw_count\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 6\n",
    "Язык - штука сложная. Люди пишут не пойми как, разные склонения/спряжения/числа/рода/знаки припинания - что делать и как быть с этим многообразием?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['canada', 'canada', 'canada', 'canada']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=[\"CANADA\",\"Canada\",\"canadA\",\"canada\"]\n",
    "lower_words=[word.lower() for word in texts]\n",
    "lower_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# init stemmer\n",
    "porter_stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>connection</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connections</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>connects</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word stemmed_word\n",
       "0       connect      connect\n",
       "1     connected      connect\n",
       "2    connection      connect\n",
       "3   connections      connect\n",
       "4      connects      connect"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem connect variations\n",
    "words=[\"connect\",\"connected\",\"connection\",\"connections\",\"connects\"]\n",
    "stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
    "\n",
    "stemdf= pd.DataFrame({'original_word': words,'stemmed_word': stemmed_words})\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trouble</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>troubled</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>troubles</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>troublemsome</td>\n",
       "      <td>troublemsom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word stemmed_word\n",
       "0       trouble       troubl\n",
       "1      troubled       troubl\n",
       "2      troubles       troubl\n",
       "3  troublemsome  troublemsom"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[\"trouble\",\"troubled\",\"troubles\",\"troublemsome\"]\n",
    "stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
    "\n",
    "stemdf= pd.DataFrame({'original_word': words,'stemmed_word': stemmed_words})\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/biryuk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# init lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>lemmatized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trouble</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>troubling</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>troubled</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>troubles</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word lemmatized_word\n",
       "0       trouble         trouble\n",
       "1     troubling         trouble\n",
       "2      troubled         trouble\n",
       "3      troubles         trouble"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[\"trouble\",\"troubling\",\"troubled\",\"troubles\",]\n",
    "lemmatized_words=[lemmatizer.lemmatize(word=word,pos='v') for word in words]\n",
    "lemmatizeddf= pd.DataFrame({'original_word': words,'lemmatized_word': lemmatized_words})\n",
    "lemmatizeddf=lemmatizeddf[['original_word','lemmatized_word']]\n",
    "lemmatizeddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>lemmatized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>goose</td>\n",
       "      <td>goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>geese</td>\n",
       "      <td>goose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word lemmatized_word\n",
       "0         goose           goose\n",
       "1         geese           goose"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[\"goose\",\"geese\"]\n",
    "lemmatized_words=[lemmatizer.lemmatize(word=word,pos='n') for word in words]\n",
    "lemmatizeddf= pd.DataFrame({'original_word': words,'lemmatized_word': lemmatized_words})\n",
    "lemmatizeddf=lemmatizeddf[['original_word','lemmatized_word']]\n",
    "lemmatizeddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['this','that','and','a','we','it','to','is','of','up','need']\n",
    "text=\"this is a text full of content and we need to clean it up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence =  this is a text full of content and we need to clean it up\n",
      "sentence with stop words removed=  W W W text full W content W W W W clean W W\n"
     ]
    }
   ],
   "source": [
    "words=text.split(\" \")\n",
    "shortlisted_words=[]\n",
    "\n",
    "#remove stop words\n",
    "for w in words:\n",
    "    if w not in stopwords:\n",
    "        shortlisted_words.append(w)\n",
    "    else:\n",
    "        shortlisted_words.append(\"W\")\n",
    "\n",
    "print(\"original sentence = \",text)    \n",
    "print(\"sentence with stop words removed= \",' '.join(shortlisted_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..trouble..</td>\n",
       "      <td>..trouble..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble&lt;</td>\n",
       "      <td>trouble&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trouble!</td>\n",
       "      <td>trouble!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;a&gt;trouble&lt;/a&gt;</td>\n",
       "      <td>&lt;a&gt;trouble&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.trouble</td>\n",
       "      <td>1.troubl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         raw_word    stemmed_word\n",
       "0     ..trouble..     ..trouble..\n",
       "1        trouble<        trouble<\n",
       "2        trouble!        trouble!\n",
       "3  <a>trouble</a>  <a>trouble</a>\n",
       "4       1.trouble        1.troubl"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_words=[\"..trouble..\",\"trouble<\",\"trouble!\",\"<a>trouble</a>\",'1.trouble']\n",
    "stemmed_words=[porter_stemmer.stem(word=word) for word in raw_words]\n",
    "stemdf= pd.DataFrame({'raw_word': raw_words,'stemmed_word': stemmed_words})\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_words(text):\n",
    "    \"\"\"Basic cleaning of texts.\"\"\"\n",
    "    \n",
    "    # remove html markup\n",
    "    text=re.sub(\"(<.*?>)\",\"\",text)\n",
    "    \n",
    "    #remove non-ascii and digits\n",
    "    text=re.sub(\"(\\\\W|\\\\d)\",\" \",text)\n",
    "    \n",
    "    #remove whitespace\n",
    "    text=text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_word</th>\n",
       "      <th>cleaned_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..trouble..</td>\n",
       "      <td>trouble</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble&lt;</td>\n",
       "      <td>trouble</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trouble!</td>\n",
       "      <td>trouble</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;a&gt;trouble&lt;/a&gt;</td>\n",
       "      <td>trouble</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.trouble</td>\n",
       "      <td>trouble</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         raw_word cleaned_word stemmed_word\n",
       "0     ..trouble..      trouble       troubl\n",
       "1        trouble<      trouble       troubl\n",
       "2        trouble!      trouble       troubl\n",
       "3  <a>trouble</a>      trouble       troubl\n",
       "4       1.trouble      trouble       troubl"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_words=[scrub_words(w) for w in raw_words]\n",
    "cleaned_stemmed_words=[porter_stemmer.stem(word=word) for word in cleaned_words]\n",
    "stemdf= pd.DataFrame({'raw_word': raw_words,'cleaned_word':cleaned_words,'stemmed_word': cleaned_stemmed_words})\n",
    "stemdf=stemdf[['raw_word','cleaned_word','stemmed_word']]\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 7\n",
    "## Пытаемся понять \"смысл\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (от англ. TF — term frequency, IDF — inverse document frequency) — статистическая мера, используемая для оценки важности слова в контексте документа, являющегося частью коллекции документов или корпуса. Вес некоторого слова пропорционален частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции.\n",
    "\n",
    "Мера TF-IDF часто используется в задачах анализа текстов и информационного поиска, например, как один из критериев релевантности документа поисковому запросу, при расчёте меры близости документов при кластеризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF (term frequency — частота слова) — отношение числа вхождений некоторого слова к общему числу слов документа. Таким образом, оценивается важность слова $t_{{i}}$ в пределах отдельного документа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\operatorname{tf}(t, d)=\\frac{n_{t}}{\\sum_{k} n_{k}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF (inverse document frequency — обратная частота документа) — инверсия частоты, с которой некоторое слово встречается в документах коллекции. Учёт IDF уменьшает вес широкоупотребительных слов. Для каждого уникального слова в пределах конкретной коллекции документов существует только одно значение IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\operatorname{idf}(t, D)=\\log \\frac{|D|}{\\left|\\left\\{d_{i} \\in D \\mid t \\in d_{i}\\right\\}\\right|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\operatorname{tf}{-\\mathrm{i}} \\mathrm{d} \\mathrm{f}(t, d, D)=\\mathrm{tf}(t, d) \\times \\mathrm{idf}(t, D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большой вес в TF-IDF получат слова с высокой частотой в пределах конкретного документа и с низкой частотой употреблений в других документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что напишем вычисление сами \"на коленке\" чтобы понять как оно работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "docA = \"The cat sat on my face\"\n",
    "docB = \"The dog sat on my bed\"\n",
    "bowA = docA.split(\" \")\n",
    "bowB = docB.split(\" \")\n",
    "wordSet = set(bowA).union(set(bowB))\n",
    "wordDictA = dict.fromkeys(wordSet, 0) \n",
    "wordDictB = dict.fromkeys(wordSet, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bowA:\n",
    "    wordDictA[word]+=1\n",
    "    \n",
    "for word in bowB:\n",
    "    wordDictB[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>bed</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>face</th>\n",
       "      <th>my</th>\n",
       "      <th>on</th>\n",
       "      <th>sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   The  bed  cat  dog  face  my  on  sat\n",
       "0    1    0    1    0     1   1   1    1\n",
       "1    1    1    0    1     0   1   1    1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfBowA = computeTF(wordDictA, bowA)\n",
    "tfBowB = computeTF(wordDictB, bowB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sat': 0.0,\n",
       " 'face': 0.3010299956639812,\n",
       " 'The': 0.0,\n",
       " 'cat': 0.3010299956639812,\n",
       " 'on': 0.0,\n",
       " 'bed': 0.3010299956639812,\n",
       " 'my': 0.0,\n",
       " 'dog': 0.3010299956639812}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])\n",
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>bed</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>face</th>\n",
       "      <th>my</th>\n",
       "      <th>on</th>\n",
       "      <th>sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   The       bed       cat       dog      face   my   on  sat\n",
       "0  0.0  0.000000  0.050172  0.000000  0.050172  0.0  0.0  0.0\n",
       "1  0.0  0.050172  0.000000  0.050172  0.000000  0.0  0.0  0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfBowA = computeTFIDF(tfBowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfBowB, idfs)\n",
    "pd.DataFrame([tfidfBowA, tfidfBowB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 8\n",
    "### Игрушки в сторону, идем в бой!\n",
    "\n",
    "Давайте применим эту механику к каким нибудь боевым задачам. Например выделить самые характирные для текста слова. Этакий бессвязный краткий пересказ.\n",
    "\n",
    "Например к постам из stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "\n",
      " accepted_answer_id          float64\n",
      "answer_count                  int64\n",
      "body                         object\n",
      "comment_count                 int64\n",
      "community_owned_date         object\n",
      "creation_date                object\n",
      "favorite_count              float64\n",
      "id                            int64\n",
      "last_activity_date           object\n",
      "last_edit_date               object\n",
      "last_editor_display_name     object\n",
      "last_editor_user_id         float64\n",
      "owner_display_name           object\n",
      "owner_user_id               float64\n",
      "post_type_id                  int64\n",
      "score                         int64\n",
      "tags                         object\n",
      "title                        object\n",
      "view_count                    int64\n",
      "dtype: object\n",
      "Number of questions,columns= (20000, 19)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read json into a dataframe\n",
    "df_idf=pd.read_json(\"stackoverflow-data-idf.json\",lines=True)\n",
    "\n",
    "# print schema\n",
    "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
    "print(\"Number of questions,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>community_owned_date</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>last_activity_date</th>\n",
       "      <th>last_edit_date</th>\n",
       "      <th>last_editor_display_name</th>\n",
       "      <th>last_editor_user_id</th>\n",
       "      <th>owner_display_name</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>post_type_id</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;I have a public class that contains a priva...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-01-27 20:19:13.563 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4821394</td>\n",
       "      <td>2011-01-27 20:21:37.59 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>163534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>c#|serialization|xml-serialization</td>\n",
       "      <td>Serializing a private struct - Can it be done?</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3367943.0</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I have the following HTML:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;cod...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-07-30 00:01:50.9 UTC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3367882</td>\n",
       "      <td>2012-05-10 14:16:05.143 UTC</td>\n",
       "      <td>2012-05-10 14:16:05.143 UTC</td>\n",
       "      <td></td>\n",
       "      <td>44390.0</td>\n",
       "      <td></td>\n",
       "      <td>1190.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>css|overflow|css-float|crop</td>\n",
       "      <td>How do I prevent floated-right content from ov...</td>\n",
       "      <td>4121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;I'm trying to run a shell script with gradl...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-07-28 16:30:18.28 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31682135</td>\n",
       "      <td>2015-07-28 16:32:15.117 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1299158.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bash|shell|android-studio|gradle</td>\n",
       "      <td>Gradle command line</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;I have an object with the following form.&lt;/...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-26 13:34:49.957 UTC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20218536</td>\n",
       "      <td>2013-11-26 15:07:50.8 UTC</td>\n",
       "      <td>2013-11-26 15:02:47.993 UTC</td>\n",
       "      <td></td>\n",
       "      <td>1333873.0</td>\n",
       "      <td></td>\n",
       "      <td>642751.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>javascript|asynchronous|foreach|async.js</td>\n",
       "      <td>Loop variable as parameter in asynchronous fun...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19941620.0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;Hi I need to valid the href is empty or not...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-12 22:41:36.11 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19941459</td>\n",
       "      <td>2013-11-12 23:48:34.67 UTC</td>\n",
       "      <td>2013-11-12 22:43:42.97 UTC</td>\n",
       "      <td></td>\n",
       "      <td>21886.0</td>\n",
       "      <td></td>\n",
       "      <td>819774.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>javascript</td>\n",
       "      <td>Canot get the href value</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accepted_answer_id  answer_count  \\\n",
       "0                 NaN             1   \n",
       "1           3367943.0             2   \n",
       "2                 NaN             0   \n",
       "3                 NaN             1   \n",
       "4          19941620.0             5   \n",
       "\n",
       "                                                body  comment_count  \\\n",
       "0  <p>I have a public class that contains a priva...              0   \n",
       "1  <p>I have the following HTML:</p>\\n\\n<pre><cod...              2   \n",
       "2  <p>I'm trying to run a shell script with gradl...              2   \n",
       "3  <p>I have an object with the following form.</...              1   \n",
       "4  <p>Hi I need to valid the href is empty or not...              1   \n",
       "\n",
       "  community_owned_date                creation_date  favorite_count        id  \\\n",
       "0                  NaN  2011-01-27 20:19:13.563 UTC             NaN   4821394   \n",
       "1                  NaN    2010-07-30 00:01:50.9 UTC             0.0   3367882   \n",
       "2                  NaN   2015-07-28 16:30:18.28 UTC             NaN  31682135   \n",
       "3                  NaN  2013-11-26 13:34:49.957 UTC             1.0  20218536   \n",
       "4                  NaN   2013-11-12 22:41:36.11 UTC             NaN  19941459   \n",
       "\n",
       "            last_activity_date               last_edit_date  \\\n",
       "0   2011-01-27 20:21:37.59 UTC                          NaN   \n",
       "1  2012-05-10 14:16:05.143 UTC  2012-05-10 14:16:05.143 UTC   \n",
       "2  2015-07-28 16:32:15.117 UTC                          NaN   \n",
       "3    2013-11-26 15:07:50.8 UTC  2013-11-26 15:02:47.993 UTC   \n",
       "4   2013-11-12 23:48:34.67 UTC   2013-11-12 22:43:42.97 UTC   \n",
       "\n",
       "  last_editor_display_name  last_editor_user_id owner_display_name  \\\n",
       "0                                           NaN                      \n",
       "1                                       44390.0                      \n",
       "2                                           NaN                      \n",
       "3                                     1333873.0                      \n",
       "4                                       21886.0                      \n",
       "\n",
       "   owner_user_id  post_type_id  score  \\\n",
       "0       163534.0             1      0   \n",
       "1         1190.0             1      2   \n",
       "2      1299158.0             1      1   \n",
       "3       642751.0             1      0   \n",
       "4       819774.0             1      0   \n",
       "\n",
       "                                       tags  \\\n",
       "0        c#|serialization|xml-serialization   \n",
       "1               css|overflow|css-float|crop   \n",
       "2          bash|shell|android-studio|gradle   \n",
       "3  javascript|asynchronous|foreach|async.js   \n",
       "4                                javascript   \n",
       "\n",
       "                                               title  view_count  \n",
       "0     Serializing a private struct - Can it be done?         296  \n",
       "1  How do I prevent floated-right content from ov...        4121  \n",
       "2                                Gradle command line         259  \n",
       "3  Loop variable as parameter in asynchronous fun...         120  \n",
       "4                           Canot get the href value          97  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хм, выглядит не очень красиво со всем кодом, но в этом все дело. Даже в таком беспорядке мы можем извлечь из этого кое-что замечательное. Хотя вы можете исключить весь код из текста, для простоты мы оставим фрагменты кода для этого руководства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'serializing a private struct can it be done i have a public class that contains a private struct the struct contains properties mostly string that i want to serialize when i attempt to serialize the struct and stream it to disk using xmlserializer i get an error saying only public types can be serialized i don t need and don t want this struct to be public is there a way i can serialize it and keep it private '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def pre_process(text):   \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_idf['text'] = df_idf['title'] + df_idf['body']\n",
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "#show the first 'text'\n",
    "df_idf['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг - начать процесс подсчета. Мы можем использовать CountVectorizer для создания словаря из всего текста в нашем df_idf ['text'] и генерировать счетчики для каждой строки в df_idf ['text']. Результатом последних двух строк является разреженное матричное представление счетчиков, означающее, что каждый столбец представляет слово в словаре, а каждая строка представляет документ в нашем наборе данных, где значения являются счетчиками слов. Обратите внимание, что в этом представлении количество слов может быть равно 0, если слово не появилось в соответствующем документе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words(\"stopwords.txt\")\n",
    "\n",
    "#get the text column \n",
    "docs=df_idf['text'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords)\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте проверим форму полученного вектора. Обратите внимание, что форма ниже (20000, 149391), потому что у нас есть 20 000 документов в нашем наборе данных (строки), а размер словаря равен 149391, что означает, что у нас есть 149391 уникальных слов (столбцов) в нашем наборе данных минус стоп-слова. В некоторых приложениях интеллектуального анализа текста, таких как кластеризация и классификация текста, мы ограничиваем размер словарного запаса.\n",
    "\n",
    "Что-ж, это легко сделать, установив max_features = vocab_size при создании экземпляра CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 124901)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biryuk/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 10000)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords,max_features=10000)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В приведенном ниже коде мы по существу берем разреженную матрицу из CountVectorizer для генерации IDF при вызове fit. **Чрезвычайно важный момент**, который следует здесь отметить, состоит в том, что IDF должен быть основан на большом корпусе текстов и должен быть репрезентативен к текстам, которые вы будете использовать для извлечения ключевых слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.37717703,  9.80492526,  9.51724319, ...,  8.82409601,\n",
       "       10.21039037,  9.51724319])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как только мы вычислили наш IDF, мы теперь готовы вычислить TF-IDF и извлечь ключевые слова. В этом примере мы извлечем ключевые слова для вопросов в stackoverflow-test.json - новых текстов статистики про которые мы не видели. Этот файл данных содержит 500 вопросов с полями, идентичными полям stackoverflow-data-idf.json, как мы видели выше. Мы начнем с чтения нашего тестового файла, извлечения необходимых полей (заголовок и тело) и получения текстов в список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test docs into a dataframe and concatenate title and body\n",
    "df_test=pd.read_json(\"stackoverflow-test.json\",lines=True)\n",
    "df_test['text'] = df_test['title'] + df_test['body']\n",
    "df_test['text'] =df_test['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "# get test docs into a list\n",
    "docs_test=df_test['text'].tolist()\n",
    "docs_title=df_test['title'].tolist()\n",
    "docs_body=df_test['body'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом является вычисление значения tf-idf для данного документа в нашем тестовом наборе путем вызова tfidf_transformer.transform (...). Эта штука сгенерирует вектор оценок tf-idf. Затем мы сортируем слова в векторе в порядке убывания значений tf-idf, а затем выполняем итерацию, чтобы извлечь элементы top-n с соответствующими именами объектов. В приведенном ниже примере мы извлекаем ключевые слова для первого документа в нашем тесте.\n",
    "\n",
    "Метод sort_coo (...) по существу сортирует значения в векторе, сохраняя при этом индекс столбца. Если у вас есть индекс столбца, тогда действительно легко найти соответствующее значение слова, как вы увидите в extract_topn_from_vector (...), где мы делаем feature_vals.append (feature_names [idx])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Integrate War-Plugin for m2eclipse into Eclipse Project\n",
      "\n",
      "=====Body=====\n",
      "<p>I set up a small web project with JSF and Maven. Now I want to deploy on a Tomcat server. Is there a possibility to automate that like a button in Eclipse that automatically deploys the project to Tomcat?</p>\n",
      "\n",
      "<p>I read about a the <a href=\"http://maven.apache.org/plugins/maven-war-plugin/\" rel=\"nofollow noreferrer\">Maven War Plugin</a> but I couldn't find a tutorial how to integrate that into my process (eclipse/m2eclipse).</p>\n",
      "\n",
      "<p>Can you link me to help or try to explain it. Thanks.</p>\n",
      "\n",
      "===Keywords===\n",
      "eclipse 0.593\n",
      "war 0.317\n",
      "integrate 0.281\n",
      "maven 0.273\n",
      "tomcat 0.27\n",
      "project 0.239\n",
      "plugin 0.214\n",
      "automate 0.157\n",
      "jsf 0.152\n",
      "possibility 0.146\n"
     ]
    }
   ],
   "source": [
    "# you only needs to do this once\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "# get the document that we want to extract keywords from\n",
    "doc=docs_test[0]\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "\n",
    "# now print the results\n",
    "print(\"\\n=====Title=====\")\n",
    "print(docs_title[0])\n",
    "print(\"\\n=====Body=====\")\n",
    "print(docs_body[0])\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из ключевых слов, приведенных выше, верхние ключевые слова действительно имеют смысл, они говорят о eclipse, maven, integrate, war и tomcat, которые являются уникальными для этого конкретного вопроса. Есть пара ключевых слов, которые можно было бы исключить, например, possibility и, возможно, даже project, и вы можете сделать это, добавив более общие слова в свой список стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь пробежимся по всему документу!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>serializing a private struct can it be done i ...</td>\n",
       "      <td>{'eclipse': 0.593, 'war': 0.317, 'integrate': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how do i prevent floated right content from ov...</td>\n",
       "      <td>{'evaluate': 0.472, 'content': 0.403, 'console...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gradle command line i m trying to run a shell ...</td>\n",
       "      <td>{'appdomain': 0.409, 'dynamic': 0.384, 'perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loop variable as parameter in asynchronous fun...</td>\n",
       "      <td>{'image': 0.424, 'jpg': 0.412, 'background': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>canot get the href value hi i need to valid th...</td>\n",
       "      <td>{'uri': 0.371, 'bitmap': 0.318, 'intent': 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how to send values to from android to a html p...</td>\n",
       "      <td>{'stylesheet': 0.466, 'font': 0.395, 'external...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>why is python s weekday different from tm_wday...</td>\n",
       "      <td>{'word': 0.526, 'getsource': 0.337, 'player': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>get new inserted id in mvc controller to jquer...</td>\n",
       "      <td>{'tcpclient': 0.364, 'ctx': 0.289, 'server': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>datagridview not showing up in webpage i m usi...</td>\n",
       "      <td>{'de': 0.585, 'whereclause': 0.317, 'grammar':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dnn linqtosql object reference not set to an i...</td>\n",
       "      <td>{'line': 0.654, 'char': 0.2, 'flex': 0.183, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cannot assign a value on a integer in bash lin...</td>\n",
       "      <td>{'listener': 0.501, 'item': 0.457, 'added': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c package relationship id i m experimenting wi...</td>\n",
       "      <td>{'amp': 0.669, 'con': 0.374, 'cmd': 0.297, 'te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wsdl java error emitter failure invalid endpoi...</td>\n",
       "      <td>{'mgoogleapiclient': 0.508, 'intent': 0.292, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how to make a uiimageview rotate around its ce...</td>\n",
       "      <td>{'user': 0.477, 'commits': 0.38, 'pushed': 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>create sitecore cshtml rendering for inserting...</td>\n",
       "      <td>{'div': 0.61, 'span': 0.458, 'checkbox': 0.396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>opengl color conversion or sdi signal conversi...</td>\n",
       "      <td>{'best': 0.435, 'perform': 0.352, 'nstimer': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>does javascript on ios have to be downloaded b...</td>\n",
       "      <td>{'proguard': 0.64, 'cordova': 0.468, 'release'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>coldfusion object to string i m really new to ...</td>\n",
       "      <td>{'subcategory': 0.612, 'category': 0.427, 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>write a list of complex numbers as binary data...</td>\n",
       "      <td>{'action': 0.417, 'align': 0.346, 'center': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rails wicked_pdf and pagination is there any s...</td>\n",
       "      <td>{'ios': 0.487, 'secret': 0.415, 'requests': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bit or bit android sdk on windows bit os inst...</td>\n",
       "      <td>{'soa': 0.515, 'articles': 0.466, 'comments': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>best way to refractor this code package com ex...</td>\n",
       "      <td>{'remove': 0.574, 'print': 0.27, 'raw_input': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>language hierarchy in java public class bllang...</td>\n",
       "      <td>{'san': 0.528, 'graphql': 0.452, 'cities': 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>call function from react component from functi...</td>\n",
       "      <td>{'invoice': 0.561, 'invoiceid': 0.401, 'nhiber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dimension independent loop over boost multi_ar...</td>\n",
       "      <td>{'parent': 0.484, 'ng': 0.44, 'scope': 0.322, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>get element being sorted within helper functio...</td>\n",
       "      <td>{'request': 0.353, 'http': 0.301, 'path': 0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>how am i supposed to get the container instanc...</td>\n",
       "      <td>{'rc': 0.616, 'mvc': 0.458, 'image': 0.334, 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>how topojson s world map scale has set in worl...</td>\n",
       "      <td>{'png': 0.405, 'phpmailer': 0.362, 'scheme': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>js events source detection i m working on a pa...</td>\n",
       "      <td>{'timestamp': 0.515, 'clientid': 0.332, 'crash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>quick algorithm of comparing sums of two array...</td>\n",
       "      <td>{'wx': 0.374, 'echo': 0.334, 'sh': 0.28, 'disa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>db driven programmatic validation asp net mvc ...</td>\n",
       "      <td>{'duration': 0.486, 'aug': 0.35, 'table': 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>can t set current day on datepickerdialog this...</td>\n",
       "      <td>{'span': 0.357, 'elements': 0.331, 'engine': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>sails can t distinguish get from post in route...</td>\n",
       "      <td>{'favicon': 0.855, 'source': 0.166, 'view': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>emacs aspect ratio definition when maximizing ...</td>\n",
       "      <td>{'photo': 0.73, 'import': 0.342, 'photos': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>r ggplot stacked columns chart i am trying to ...</td>\n",
       "      <td>{'axes': 0.642, 'size': 0.32, 'figure': 0.231,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>how to do delete define with using idcams usin...</td>\n",
       "      <td>{'lang': 0.474, 'visits': 0.404, 'router': 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>read multiple netcdf files matlab i have netcd...</td>\n",
       "      <td>{'userid': 0.498, 'var': 0.345, 'nil': 0.242, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>ios app hanging on splash screen compatibility...</td>\n",
       "      <td>{'init': 0.592, 'url': 0.432, 'ios': 0.373, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>httpwebrequest requesturi scheme always return...</td>\n",
       "      <td>{'value': 0.474, 'cast': 0.43, 'datetime': 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>foreign keys on two different schemas mysql i ...</td>\n",
       "      <td>{'parent': 0.45, 'tfs': 0.358, 'possibility': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>retrieving a qstandarditem through qstandardit...</td>\n",
       "      <td>{'custom': 0.467, 'marker': 0.444, 'control': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>wxwidgets right to left direction i have a wxw...</td>\n",
       "      <td>{'ptr': 0.458, 'test': 0.325, 'cpp': 0.273, 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>asp net rendercontrol or renderchildren fail i...</td>\n",
       "      <td>{'module': 0.375, 'byte': 0.358, 'field': 0.34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>quicky getting out of the catch block i have a...</td>\n",
       "      <td>{'td': 0.588, 'tr': 0.366, 'align': 0.301, 'ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>how to fix my social sharing buttons on wordpr...</td>\n",
       "      <td>{'vw': 0.679, 'interaction': 0.423, 'thats': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>c cli attributes i am trying to create a custo...</td>\n",
       "      <td>{'textfield': 0.726, 'piece': 0.186, 'public':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>jquery to perform regexp multiple options i m ...</td>\n",
       "      <td>{'section': 0.693, 'div': 0.393, 'flex': 0.325...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>calling parent function with the same signatur...</td>\n",
       "      <td>{'database': 0.319, 'schema': 0.291, 'backup':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>how i use bing maps api for wpf with another l...</td>\n",
       "      <td>{'share': 0.656, 'branch': 0.313, 'android': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>launch a xcodeproj from terminal i trying to b...</td>\n",
       "      <td>{'icon': 0.455, 'map': 0.324, 'gevent': 0.265,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>habtm additional fields in join table i m havi...</td>\n",
       "      <td>{'credit': 0.666, 'refid': 0.404, 'save': 0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>jquery checkbox input validation i have the fo...</td>\n",
       "      <td>{'hg': 0.685, 'root': 0.344, 'mar': 0.266, 'dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>how to upload the picture to aws s bucket gett...</td>\n",
       "      <td>{'objects': 0.444, 'color': 0.418, 'self': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>laravel forward to error page i am using larav...</td>\n",
       "      <td>{'amazon': 0.583, 'app': 0.373, 'installed': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>php select function generates weird where clau...</td>\n",
       "      <td>{'interface': 0.437, 'px': 0.288, 'click': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>how to unbind click and click submit button in...</td>\n",
       "      <td>{'delphi': 0.617, 'compatible': 0.365, 'win': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>swaggerui auth redirect swaggeruiauth of null ...</td>\n",
       "      <td>{'node': 0.547, 'selectsinglenode': 0.304, 'nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ssrs value display error for ssrs conditional ...</td>\n",
       "      <td>{'logo': 0.549, 'step': 0.33, 'triangle': 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>accessing and changing a class instance from a...</td>\n",
       "      <td>{'length': 0.426, 'ev': 0.415, 'introduce': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>how to print the current time in the format da...</td>\n",
       "      <td>{'oauth': 0.388, 'localhost': 0.383, 'sdk': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   doc  \\\n",
       "0    serializing a private struct can it be done i ...   \n",
       "1    how do i prevent floated right content from ov...   \n",
       "2    gradle command line i m trying to run a shell ...   \n",
       "3    loop variable as parameter in asynchronous fun...   \n",
       "4    canot get the href value hi i need to valid th...   \n",
       "5    how to send values to from android to a html p...   \n",
       "6    why is python s weekday different from tm_wday...   \n",
       "7    get new inserted id in mvc controller to jquer...   \n",
       "8    datagridview not showing up in webpage i m usi...   \n",
       "9    dnn linqtosql object reference not set to an i...   \n",
       "10   cannot assign a value on a integer in bash lin...   \n",
       "11   c package relationship id i m experimenting wi...   \n",
       "12   wsdl java error emitter failure invalid endpoi...   \n",
       "13   how to make a uiimageview rotate around its ce...   \n",
       "14   create sitecore cshtml rendering for inserting...   \n",
       "15   opengl color conversion or sdi signal conversi...   \n",
       "16   does javascript on ios have to be downloaded b...   \n",
       "17   coldfusion object to string i m really new to ...   \n",
       "18   write a list of complex numbers as binary data...   \n",
       "19   rails wicked_pdf and pagination is there any s...   \n",
       "20    bit or bit android sdk on windows bit os inst...   \n",
       "21   best way to refractor this code package com ex...   \n",
       "22   language hierarchy in java public class bllang...   \n",
       "23   call function from react component from functi...   \n",
       "24   dimension independent loop over boost multi_ar...   \n",
       "25   get element being sorted within helper functio...   \n",
       "26   how am i supposed to get the container instanc...   \n",
       "27   how topojson s world map scale has set in worl...   \n",
       "28   js events source detection i m working on a pa...   \n",
       "29   quick algorithm of comparing sums of two array...   \n",
       "..                                                 ...   \n",
       "470  db driven programmatic validation asp net mvc ...   \n",
       "471  can t set current day on datepickerdialog this...   \n",
       "472  sails can t distinguish get from post in route...   \n",
       "473  emacs aspect ratio definition when maximizing ...   \n",
       "474  r ggplot stacked columns chart i am trying to ...   \n",
       "475  how to do delete define with using idcams usin...   \n",
       "476  read multiple netcdf files matlab i have netcd...   \n",
       "477  ios app hanging on splash screen compatibility...   \n",
       "478  httpwebrequest requesturi scheme always return...   \n",
       "479  foreign keys on two different schemas mysql i ...   \n",
       "480  retrieving a qstandarditem through qstandardit...   \n",
       "481  wxwidgets right to left direction i have a wxw...   \n",
       "482  asp net rendercontrol or renderchildren fail i...   \n",
       "483  quicky getting out of the catch block i have a...   \n",
       "484  how to fix my social sharing buttons on wordpr...   \n",
       "485  c cli attributes i am trying to create a custo...   \n",
       "486  jquery to perform regexp multiple options i m ...   \n",
       "487  calling parent function with the same signatur...   \n",
       "488  how i use bing maps api for wpf with another l...   \n",
       "489  launch a xcodeproj from terminal i trying to b...   \n",
       "490  habtm additional fields in join table i m havi...   \n",
       "491  jquery checkbox input validation i have the fo...   \n",
       "492  how to upload the picture to aws s bucket gett...   \n",
       "493  laravel forward to error page i am using larav...   \n",
       "494  php select function generates weird where clau...   \n",
       "495  how to unbind click and click submit button in...   \n",
       "496  swaggerui auth redirect swaggeruiauth of null ...   \n",
       "497  ssrs value display error for ssrs conditional ...   \n",
       "498  accessing and changing a class instance from a...   \n",
       "499  how to print the current time in the format da...   \n",
       "\n",
       "                                              keywords  \n",
       "0    {'eclipse': 0.593, 'war': 0.317, 'integrate': ...  \n",
       "1    {'evaluate': 0.472, 'content': 0.403, 'console...  \n",
       "2    {'appdomain': 0.409, 'dynamic': 0.384, 'perfor...  \n",
       "3    {'image': 0.424, 'jpg': 0.412, 'background': 0...  \n",
       "4    {'uri': 0.371, 'bitmap': 0.318, 'intent': 0.30...  \n",
       "5    {'stylesheet': 0.466, 'font': 0.395, 'external...  \n",
       "6    {'word': 0.526, 'getsource': 0.337, 'player': ...  \n",
       "7    {'tcpclient': 0.364, 'ctx': 0.289, 'server': 0...  \n",
       "8    {'de': 0.585, 'whereclause': 0.317, 'grammar':...  \n",
       "9    {'line': 0.654, 'char': 0.2, 'flex': 0.183, 'c...  \n",
       "10   {'listener': 0.501, 'item': 0.457, 'added': 0....  \n",
       "11   {'amp': 0.669, 'con': 0.374, 'cmd': 0.297, 'te...  \n",
       "12   {'mgoogleapiclient': 0.508, 'intent': 0.292, '...  \n",
       "13   {'user': 0.477, 'commits': 0.38, 'pushed': 0.3...  \n",
       "14   {'div': 0.61, 'span': 0.458, 'checkbox': 0.396...  \n",
       "15   {'best': 0.435, 'perform': 0.352, 'nstimer': 0...  \n",
       "16   {'proguard': 0.64, 'cordova': 0.468, 'release'...  \n",
       "17   {'subcategory': 0.612, 'category': 0.427, 'mod...  \n",
       "18   {'action': 0.417, 'align': 0.346, 'center': 0....  \n",
       "19   {'ios': 0.487, 'secret': 0.415, 'requests': 0....  \n",
       "20   {'soa': 0.515, 'articles': 0.466, 'comments': ...  \n",
       "21   {'remove': 0.574, 'print': 0.27, 'raw_input': ...  \n",
       "22   {'san': 0.528, 'graphql': 0.452, 'cities': 0.3...  \n",
       "23   {'invoice': 0.561, 'invoiceid': 0.401, 'nhiber...  \n",
       "24   {'parent': 0.484, 'ng': 0.44, 'scope': 0.322, ...  \n",
       "25   {'request': 0.353, 'http': 0.301, 'path': 0.26...  \n",
       "26   {'rc': 0.616, 'mvc': 0.458, 'image': 0.334, 'a...  \n",
       "27   {'png': 0.405, 'phpmailer': 0.362, 'scheme': 0...  \n",
       "28   {'timestamp': 0.515, 'clientid': 0.332, 'crash...  \n",
       "29   {'wx': 0.374, 'echo': 0.334, 'sh': 0.28, 'disa...  \n",
       "..                                                 ...  \n",
       "470  {'duration': 0.486, 'aug': 0.35, 'table': 0.32...  \n",
       "471  {'span': 0.357, 'elements': 0.331, 'engine': 0...  \n",
       "472  {'favicon': 0.855, 'source': 0.166, 'view': 0....  \n",
       "473  {'photo': 0.73, 'import': 0.342, 'photos': 0.2...  \n",
       "474  {'axes': 0.642, 'size': 0.32, 'figure': 0.231,...  \n",
       "475  {'lang': 0.474, 'visits': 0.404, 'router': 0.3...  \n",
       "476  {'userid': 0.498, 'var': 0.345, 'nil': 0.242, ...  \n",
       "477  {'init': 0.592, 'url': 0.432, 'ios': 0.373, 'm...  \n",
       "478  {'value': 0.474, 'cast': 0.43, 'datetime': 0.3...  \n",
       "479  {'parent': 0.45, 'tfs': 0.358, 'possibility': ...  \n",
       "480  {'custom': 0.467, 'marker': 0.444, 'control': ...  \n",
       "481  {'ptr': 0.458, 'test': 0.325, 'cpp': 0.273, 'i...  \n",
       "482  {'module': 0.375, 'byte': 0.358, 'field': 0.34...  \n",
       "483  {'td': 0.588, 'tr': 0.366, 'align': 0.301, 'ce...  \n",
       "484  {'vw': 0.679, 'interaction': 0.423, 'thats': 0...  \n",
       "485  {'textfield': 0.726, 'piece': 0.186, 'public':...  \n",
       "486  {'section': 0.693, 'div': 0.393, 'flex': 0.325...  \n",
       "487  {'database': 0.319, 'schema': 0.291, 'backup':...  \n",
       "488  {'share': 0.656, 'branch': 0.313, 'android': 0...  \n",
       "489  {'icon': 0.455, 'map': 0.324, 'gevent': 0.265,...  \n",
       "490  {'credit': 0.666, 'refid': 0.404, 'save': 0.26...  \n",
       "491  {'hg': 0.685, 'root': 0.344, 'mar': 0.266, 'dr...  \n",
       "492  {'objects': 0.444, 'color': 0.418, 'self': 0.2...  \n",
       "493  {'amazon': 0.583, 'app': 0.373, 'installed': 0...  \n",
       "494  {'interface': 0.437, 'px': 0.288, 'click': 0.2...  \n",
       "495  {'delphi': 0.617, 'compatible': 0.365, 'win': ...  \n",
       "496  {'node': 0.547, 'selectsinglenode': 0.304, 'nu...  \n",
       "497  {'logo': 0.549, 'step': 0.33, 'triangle': 0.32...  \n",
       "498  {'length': 0.426, 'ev': 0.415, 'introduce': 0....  \n",
       "499  {'oauth': 0.388, 'localhost': 0.383, 'sdk': 0....  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate tf-idf for all documents in your list. docs_test has 500 documents\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform(docs_test))\n",
    "\n",
    "results=[]\n",
    "for i in range(tf_idf_vector.shape[0]):\n",
    "    \n",
    "    # get vector for a single document\n",
    "    curr_vector=tf_idf_vector[i]\n",
    "    \n",
    "    #sort the tf-idf vector by descending order of scores\n",
    "    sorted_items=sort_coo(curr_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    \n",
    "    results.append(keywords)\n",
    "\n",
    "df=pd.DataFrame(zip(docs,results),columns=['doc','keywords'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
